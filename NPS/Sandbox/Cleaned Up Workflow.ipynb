{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66fedac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# logging (set to INFO)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "#genism\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c92e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('reddit_data_one-year.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb5637dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "data['text'] = data.text.map(alphanumeric).map(punc_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9291447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_corpus = ['amphetamine', 'clonazolam','dopamine','methylphenidate', 'bromazolam', 'triptamine', 'dmt', 'mxe','fxe','flubromazolam','triazolam','flualprazolam',\n",
    " 'arylcyclohexylamine','acetone','chloride','etizolam','alprazolam','dinotrogen','dpt','dck','bromazepam',\n",
    " 'lorazepam','trazodone','mirtazapine','ketamine','klonopin','propranolol','fluclotizolam','diclazepam',\n",
    " 'norflurazepam','quetiapine','xan','hydrochloride','aplrazolam','phenethylamine','bretazenil',\n",
    " 'rilmazafone','pyrazolam','emoxypine','fasoracetam','mda','tyrosine','diazepam','phenylpiracetam','pvp','flunitrazolam',\n",
    " 'cyclazodone','thc','dexamphetamine','benzene','piracetam','benzodiazepine','diazepine','tryptamine',\n",
    " 'diclaz','metizolam','flubrotizolam','mescaline','hydroxytryptamine',\n",
    " 'dimethyltryptamine',\n",
    " 'clonazepam',\n",
    " 'clonzolam',\n",
    " 'doxylamine',\n",
    " 'diphenydramine',\n",
    " 'ket',\n",
    " 'allylescaline',\n",
    " 'phenylethylamine',\n",
    " 'oxy',\n",
    " 'nitrazolam',\n",
    " 'clonozolam',\n",
    " 'dopamine',\n",
    " 'etazene',\n",
    " 'methylamphetamine',\n",
    " 'phenidate',\n",
    " 'mth',\n",
    " 'dextroamphetamine',\n",
    " 'midazolam',\n",
    " 'methamphetamine',\n",
    " 'fluoroamphetamine',\n",
    " 'ethyltryptamine',\n",
    " 'ethylamine',\n",
    " 'flouromethamphetamine',\n",
    " 'methoxetamine',\n",
    " 'cyclaz',\n",
    " 'zylofuramine',\n",
    " 'cypenamine',\n",
    " 'ephenidine',\n",
    " 'ketamine',\n",
    " 'flumazenil',\n",
    " 'xtc',\n",
    " 'monoamine',\n",
    " 'methallylescaline',\n",
    " 'methallyescaline',\n",
    " 'propanolol',\n",
    " 'tapentadol',\n",
    " 'esketamine',\n",
    " 'sine',\n",
    " 'isopropylphenidate',\n",
    " 'ethylphenidate',\n",
    " 'diphenhydramine',\n",
    " 'metodesnitazene',\n",
    " 'fluonitazene',\n",
    " 'tiletamine',\n",
    " 'flubromzolam',\n",
    " 'isotonitazene',\n",
    " 'proppranolol',\n",
    " 'racetam','desoxymethoxetamine','imidazenil','isopropyphenidate','propylphenidate','fluoromethylphenidate','lisdexamphetamine','isoproscaline','isopropoxyphenethylamine','mhp','lisdexamfetamine','flourodeschloroketamine','sulbutiamine','trpytamine','methiopropamine','methalyescaline','flurazepam','olanzapine','dizocilpine','nimetazepam','methylenedioxymethamphetamine',\n",
    " 'etonitazene','lormetazepam','flunitrazepam','dxe','temazepam','oxazepam','ephinidine','thiamine','tryosine',\n",
    " 'bromozolam','isopropylphenidine','chloroephenidine','hydroxymetamine','pcm',\n",
    " 'methoxyketamine','norketamine','cyclopropylmescaline','dichloromescaline','dibromomescaline','hodgkinsine','phenazepam',\n",
    " 'brotizolam','hearthstone','methallallylescaline','deoxymethoxetamine',\n",
    " 'zolam', 'methoxpropamine', 'metilphenidate', 'deschloroketamine', 'itonitazene','benzos',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31827974",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"stop_words_english.txt\", \"r\")\n",
    "\n",
    "corpus1 = [s.strip() for s in a_file.readlines()]\n",
    "\n",
    "for line in a_file:\n",
    "  stripped_line = line.strip()\n",
    "  line_list = stripped_line.split()\n",
    "  list_of_lists.append(line_list)\n",
    "\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f9daaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_topics(docs, preprocessor, vectorizer, topic_modeler, print_n_words=15):\n",
    "    \"\"\"A very simple pipeline.\"\"\"\n",
    "    \n",
    "    # Apply preprocessor, vectorizer, and topic modeler.\n",
    "    if preprocessor is not None:\n",
    "        docs = docs.apply(preprocessor)\n",
    "    \n",
    "    # Vectorize documents into a document-word matrix.\n",
    "    doc_word_vectors = vectorizer.fit_transform(docs)\n",
    "    \n",
    "    # Fit the topic model.\n",
    "    doc_topic_vectors = topic_modeler.fit_transform(doc_word_vectors)\n",
    "    \n",
    "    # Print the topics.\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "    for idx, topic in enumerate(topic_modeler.components_):\n",
    "        # Select the top 15 words in vocab for this topic.\n",
    "        top_words = [vocab[i].upper() for i in topic.argsort()[:-print_n_words-1:-1]]\n",
    "        print(f\"Topic {idx}:\\n\", \", \".join(top_words), \"\\n\")\n",
    "    \n",
    "    return doc_topic_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c6913b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "256be9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brightening'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('brightening')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea245be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered2 = []\n",
    "for i in data.text:\n",
    "    new_data = i.split()\n",
    "    post_filter = []\n",
    "    for i in new_data:\n",
    "        i = lemmatizer.lemmatize(i)\n",
    "        #i = stemmer.stem(i)\n",
    "        if i not in drug_corpus and corpus1 and len(i) > 2:\n",
    "            post_filter.append(i)\n",
    "    post_filter = ' '.join(post_filter)\n",
    "    filtered2.append(post_filter)  \n",
    "data['removed_drug_words'] = filtered2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "280f5684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>counter</th>\n",
       "      <th>removed_drug_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>took one tab   of it   at am and felt the firs...</td>\n",
       "      <td>495</td>\n",
       "      <td>took one tab and felt the first effect min lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>took one tab   at   am and felt the first effe...</td>\n",
       "      <td>506</td>\n",
       "      <td>took one tab and felt the first effect min lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>so my brain was virgin and i used both   and  ...</td>\n",
       "      <td>530</td>\n",
       "      <td>brain virgin and used both and daily for funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amp    \\n\\noptical brightening agents  obas  ...</td>\n",
       "      <td>144</td>\n",
       "      <td>amp optical brightening agent obas also known ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i’ve fucked around with pressed bars for quite...</td>\n",
       "      <td>166</td>\n",
       "      <td>i’ve fucked around with pressed bar for quite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>of first   lsd dose as recommended by the fe...</td>\n",
       "      <td>243</td>\n",
       "      <td>first lsd dose recommended the few place aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>hello all\\n\\nhas anyone tried  mfpvp    the ch...</td>\n",
       "      <td>142</td>\n",
       "      <td>hello all anyone tried mfpvp the chemical stru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>tldr  i have a tolerance   am i able to get so...</td>\n",
       "      <td>226</td>\n",
       "      <td>tldr have tolerance able get some magic again ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>so i ve been doing some research  and i ve see...</td>\n",
       "      <td>188</td>\n",
       "      <td>been doing some research and seen lot conflict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>i decided to buy doc as my first rc bc i wante...</td>\n",
       "      <td>210</td>\n",
       "      <td>decided buy doc first wanted something that is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  counter  \\\n",
       "0     took one tab   of it   at am and felt the firs...      495   \n",
       "1     took one tab   at   am and felt the first effe...      506   \n",
       "2     so my brain was virgin and i used both   and  ...      530   \n",
       "3      amp    \\n\\noptical brightening agents  obas  ...      144   \n",
       "4     i’ve fucked around with pressed bars for quite...      166   \n",
       "...                                                 ...      ...   \n",
       "1026    of first   lsd dose as recommended by the fe...      243   \n",
       "1027  hello all\\n\\nhas anyone tried  mfpvp    the ch...      142   \n",
       "1028  tldr  i have a tolerance   am i able to get so...      226   \n",
       "1029  so i ve been doing some research  and i ve see...      188   \n",
       "1030  i decided to buy doc as my first rc bc i wante...      210   \n",
       "\n",
       "                                     removed_drug_words  \n",
       "0     took one tab and felt the first effect min lat...  \n",
       "1     took one tab and felt the first effect min lat...  \n",
       "2     brain virgin and used both and daily for funct...  \n",
       "3     amp optical brightening agent obas also known ...  \n",
       "4     i’ve fucked around with pressed bar for quite ...  \n",
       "...                                                 ...  \n",
       "1026  first lsd dose recommended the few place aroun...  \n",
       "1027  hello all anyone tried mfpvp the chemical stru...  \n",
       "1028  tldr have tolerance able get some magic again ...  \n",
       "1029  been doing some research and seen lot conflict...  \n",
       "1030  decided buy doc first wanted something that is...  \n",
       "\n",
       "[1031 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3088eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      " DAY, SLEEP, WEEK, NIGHT, TAKING, MONTH, BENZO, WORK, ANXIETY, YEAR, USING, WITHDRAWAL, TOOK, AGO, TOLERANCE \n",
      "\n",
      "Topic 1:\n",
      " TRIP, LSD, MET, VISUALS, LAD, ACO, TAB, EXPERIENCE, WANT, ACID, PSYCHEDELICS, TRIPPING, SHROOMS, DOSE, HEADSPACE \n",
      "\n",
      "Topic 2:\n",
      " DRUG, KNOW, PEOPLE, DON, WANT, THINK, LIFE, USE, GUY, THING, RESEARCH, NEW, RCS, CHEMICAL, SHIT \n",
      "\n",
      "Topic 3:\n",
      " EFFECT, DOSE, HOUR, FEEL, DOS, EXPERIENCE, TOLERANCE, EUPHORIA, SUBSTANCE, ORAL, HIGH, SIMILAR, EUPHORIC, LITTLE, TRIED \n",
      "\n",
      "Topic 4:\n",
      " FELT, FEELING, FEEL, BODY, REALLY, THOUGHT, TOOK, MINUTE, EYE, DIDN, STARTED, MUSIC, DECIDED, HOUR, GOT \n",
      "\n",
      "Topic 5:\n",
      " SOLUTION, WATER, POWDER, BOTTLE, DISSOLVE, DROP, SPRAY, ETHANOL, DOSE, MAKE, SOLUBLE, MIX, SOLVENT, USING, WAY \n",
      "\n",
      "Topic 6:\n",
      " PCP, MEO, PCE, DISSOS, MXIPR, DMXE, MIPT, DISSO, AMP, MANIA, COMPOUND, HOLE, REALLY, MXPR, EXPERIENCE \n",
      "\n",
      "Topic 7:\n",
      " FMA, VYVANSE, STIMULANT, DAY, STIM, GOOD, ORALLY, WORK, MMC, FPM, REALLY, WEEK, STIMS, MAPB, SERT \n",
      "\n",
      "Topic 8:\n",
      " HTTP, AMP, COM, WWW, ORG, RESEARCHCHEMICALS, REDDIT, COMMENT, WIKI, SUBSTANCE, IMGUR, INFORMATION, NOVEL, LINK, ACID \n",
      "\n",
      "Topic 9:\n",
      " MDMA, MAPB, APB, MMC, COMEDOWN, ROLL, FLY, COMBO, SEROTONIN, AMP, FLIP, EXPERIENCE, PHENIBUT, REDOSE, MONTH \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    }
   ],
   "source": [
    "docs = data['removed_drug_words']\n",
    "preprocessor = None\n",
    "vectorizer = TfidfVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 5)  # Single change to add in common English stop words.\n",
    "\n",
    "topic_modeler = NMF(10, random_state=10)\n",
    "\n",
    "make_topics(docs, preprocessor, vectorizer, topic_modeler);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed2329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
