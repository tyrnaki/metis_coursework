# Modeling the DC Area Real Estate Market
Walter Tyrna

## Abstract
The goal of this project is to create a model that can determine the most important factors that drive a given property's final sale price. The model also should reasonably predict a property's final sale price.
This information would help home sellers and investors determine how to best match asking price with a property's potential sales price. 

I used data scraped from Compass (https://www.compass.com/), a major DC-area real estate company, for real estate listings in conjunction with some information scraped from DC Metro's website (https://www.wmata.com/) to develop models using Linear Regression and Lasso modeling techniques. I used tables generated by Pandas and Folium to communicate my results.

## Design
This project considered features that relate to a property's physical state (such as beds/baths, stories, etc) as well as physical location (in terms of zipcode/general area as well as distance from downtown and metro stations).

Identifying features that most impact a property's ultimate sales price can not only help a seller adequately determine an sales price, but also determine what physical features can be improved (or left alone) to improve a property's sales price. For example, whether or not adding a bedroom or building a garage would be worth the investment. 


## Data
The original dataset included over 2,500 real estate listings with 15 inital features (6 categorical). To inform the distance-related features, coordinates for the DC area's 91 metro stations were included.
These 2,500 listings were scoped to include only single-family/townhomes within 25mi of downtown DC, yeilding under 1,000 listings for analysis. The listing's features were down-selected during the feature engineering process.

## Algorithms
*EDA*
1. Cleaning scraped data for nulls or irrelevant data.
2. Identifying and removing outliers.
3. Determining geographic information for each property.

*Feature Engineering*
1.  Creating correlation heatmap using Seaborn to determine collinearity among features & removing colinear features.
2.  Converting categorical features to binary dummy variables; removing features that act as binary (yes, no)
3.  Creating secondary correlation heatmap with categorial features to further downselect
4.  Determining the correlation of each feature with the target (Sold Price), downselecting features to only those with an absoulte value of > 0.1

*Models*
  
This project used Linear regression and Lasso regression in order to maintain model interpretability. Both models used K-fold to improve R2 confidence. 

*Model Evaluation and Selection*
  
The data was split using train_test_split. When evaluated with different models, the data was split and randomly validated through k-fold (5 splits). Between Linear Regression and Lasso Regression, Lasso resulted in better R^2 scores.

**Linear Regression Scores:** 
   - Train R2: 0.8579
   - Test R2: 0.8617

**Lasso Regression Scores:** 
   - Train R2: 0.8580
   - Test R2: 0.8622
   - MAE: $89,836

The scores above include "tax assessed value" as a feature. While this is a dollar-value figure, it is important in determining a home's value and often is a benchmark from which home values are built upon. Excluding the feature yeilded a much lower R^2 and a higher MAE, as compared to the above. As a result, I highlight values that include the tax assessed value.

**Linear Regression Scores w/o tax assessed value:** 
   - Train R2: 0.0.494
   - Test R2: 0.454

**Lasso Regression Scores w/o tax assessed value:** 
   - Train R2: 0.0.494
   - Test R2: 0.454
   - MAE: $197,647

## Tools
- BeautifulSoup for web scraping
- Numpy and Pandas for data manipulation
- Scikit-learn for modeling
- Matplotlib, Seaborn, Plotly for plotting & visualizations
- Geopy and Folium for geographic data & visualizations
- TQDM for function validation

## Communication
Slides and visuals presented
